{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93d62d6d-64e3-4b6c-9576-b5565f90cf64",
   "metadata": {
    "id": "93d62d6d-64e3-4b6c-9576-b5565f90cf64"
   },
   "source": [
    "# Health Information Systems and Decision Support Systems\n",
    "## WPO 3: Data-driven systems 1: Regression  (01/03/24)\n",
    "***\n",
    "*Jakub Ceranka, Joris Wuts, Jef Vandemeulebroucke* <br>\n",
    "*Department of Electronics and Informatics (ETRO)* <br>\n",
    "*Vrije Universiteit Brussel, Pleinlaan 2, B-1050 Brussels, Belgium*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c88022-adce-476a-a035-4d69cb28e710",
   "metadata": {
    "id": "99c88022-adce-476a-a035-4d69cb28e710"
   },
   "source": [
    "<font color=blue>Insert students names and IDs here</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7141cc3c-a6e1-4208-8c66-fbb64a5fc33a",
   "metadata": {
    "id": "7141cc3c-a6e1-4208-8c66-fbb64a5fc33a"
   },
   "source": [
    "***\n",
    "### Goal\n",
    "The goal of this practical session is to get an insight into logistic regression modelling using real life medical data from patients infected with COVID-19. Your tasks will involve building different models to predict disease severity and analyze the relations between different variables and severity risk. Students must send their notebook using the Assignment functionality in Canvas before the __7th of March, 2023, 23:59. Remember to include the HTML format!__ The grade from this practical session will contribute to your final grade.\n",
    "Questions: on the discusion channel on canvas\n",
    "***\n",
    "In this practical session you will predict the severity of the COVID-19 outcome, based on the analysis of patient information and the corresponding computed tomography (CT) images features of COVID-19 suspects and actual patients suffering from COVID-19.\n",
    "***\n",
    "#### COVID features dataset\n",
    "Have a look at the provided COVID datasheet (*COVID_data.csv*) with multiple features describing various COVID patients and suspects. The dataset consist of 2000 data points with multiple features, each datapoint representing an actual COVID-patient or a COVID-suspect.\n",
    "\n",
    "The contents of the feaures provide the following information:\n",
    "*   *PatientID*: ID of the patient\n",
    "*   *Age*: Age of the patient categorized into one of 6 categories to limit the risk of deanonimization.\n",
    "*   *Sex*: M or F - patient gender\n",
    "*   *Covid*: Indicates whether the patient had a confirmed COVID infection\n",
    "*   *Severity*: For COVID patients, indicates whether the disease was severe (need for intubation or caused patient death)\n",
    "*   *Image_size* and *Spacing* are CT image parameters used for imaging\n",
    "*   *GGO*: Proportion of the lung with GGO. Ground glass opacity (*GGO*) refers to the hazy gray areas that can show up in CT scans or X-rays of the lungs. These gray areas indicate increased density inside the lungs. The term comes from a technique in glassmaking during which the surface of the glass is blasted by sand.\n",
    "*   *Consolidation*: Proportion of the lung with consolidated lessions. A pulmonary consolidation is a region of normally compressible lung tissue that has filled with liquid instead of air.\n",
    "\n",
    "Two last features (*GGO* and *Consolidation*) were extracted from CT images of patients with COVID, or suspects of having COVID, and the ratio to the total lung volume is provided.\n",
    "\n",
    "<img src=\"GGO.jpeg\" alt=\"Drawing\" style=\"width: 600px;\"/>\n",
    "\n",
    "High-resolution CT image showing ground-glass opacities in the periphery of both lungs in a patient with COVID-19 (red arrows). The adjacent normal lung tissue with lower attenuation appears as darker areas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6584b8-5ae9-41e1-b3fd-fa646ec40edb",
   "metadata": {
    "id": "eb6584b8-5ae9-41e1-b3fd-fa646ec40edb"
   },
   "source": [
    "### Importing packages\n",
    "\n",
    "During this lab session you will need a couple of packages, run the following cell to import pandas, numpy, seaborn and matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "D5fPXiCWX5fj",
   "metadata": {
    "id": "D5fPXiCWX5fj"
   },
   "outputs": [],
   "source": [
    "!pip install statkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4d359d-d063-46df-a5af-81e9d350ab11",
   "metadata": {
    "id": "7d4d359d-d063-46df-a5af-81e9d350ab11"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed32502a-d387-4c44-a392-c1a6e4e68864",
   "metadata": {
    "id": "ed32502a-d387-4c44-a392-c1a6e4e68864"
   },
   "source": [
    "***\n",
    "## Part 1: Loading, cleaning and analyzing the data\n",
    "### Task 1.1 Loading and cleaning the data\n",
    "Lets read the data into the dataframe `data`.\n",
    "\n",
    "Inspect the dataframe and drop the following columns : `Images_sizes, Spacings, PatientID`.\n",
    "\n",
    "Your processed dataframe should have a shape of `(2000,6)`.\n",
    "\n",
    "Please call your final dataframe `df` throughout the whole lab session, as we provide code snipets in Task 2 and 3 that assume this variable name for the dataframe.\n",
    "\n",
    "To further use the dataframe, we need to binarize the `Sex` label. Binarize the column so that male patients have a value of 1 and females of 0. Finally, filter the dataframe so it only has COVID positive patients. After filtering you can also drop the COVID column.\n",
    "\n",
    "Your final dataframe should be a shape of `(1205, 5)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f256593-0f01-430e-9f67-a431267b869d",
   "metadata": {
    "id": "2f256593-0f01-430e-9f67-a431267b869d"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302e9289-dcc8-45e9-b59d-0d0ae3c11cf0",
   "metadata": {
    "id": "302e9289-dcc8-45e9-b59d-0d0ae3c11cf0"
   },
   "source": [
    "***\n",
    "### Task 1.2: Assess the severity of COVID-19 in function of age\n",
    "\n",
    "Plot a histogram for the different age groups. Note, that the ages are categorical at 6 fixed values.\n",
    "\n",
    "__Hint:__ Use seaborns `histplot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8f424b-2b60-4f2f-9903-09a19d5c75b7",
   "metadata": {
    "id": "4b8f424b-2b60-4f2f-9903-09a19d5c75b7"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52428de-69ca-47cf-b666-b69f9712777a",
   "metadata": {
    "id": "c52428de-69ca-47cf-b666-b69f9712777a"
   },
   "source": [
    "### Question 1.1: What can you conclude from this plots?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bedd05-ce55-4819-b5cc-5944c9be3bdf",
   "metadata": {
    "id": "15bedd05-ce55-4819-b5cc-5944c9be3bdf"
   },
   "source": [
    "Answer to question 1.1: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9a028-be09-4887-bc56-add125dbaa9e",
   "metadata": {
    "id": "e1a9a028-be09-4887-bc56-add125dbaa9e",
    "tags": []
   },
   "source": [
    "***\n",
    "### Task 1.3: Checking the impact of GGO, consolidation and sex on the COVID severity\n",
    "\n",
    "Now make similar two kde plots to assess the correlations between the `GGO`, `Consolidation` vs `Severity`.\n",
    "\n",
    "To assess the impact of `sex`  we will use a different plot. Use a scatter plot to plot the mean fraction of severity per age group. Use 2 different colours for male and female patients.\n",
    "\n",
    "__hint__: Split the dataframe into 2 new dataframes containing only 1 sex. Then use the groupby functionality to agregate information per age group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867d70a-889a-4f0f-9121-dbe8cd9bab7e",
   "metadata": {
    "id": "7867d70a-889a-4f0f-9121-dbe8cd9bab7e"
   },
   "outputs": [],
   "source": [
    "# GGO vs Severity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d79db6-1768-4ac3-a503-329a95fcd231",
   "metadata": {
    "id": "37d79db6-1768-4ac3-a503-329a95fcd231"
   },
   "outputs": [],
   "source": [
    "# Consolidation vs Severity plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f788993-e765-4af4-b5ea-5c3758bff8c4",
   "metadata": {
    "id": "0f788993-e765-4af4-b5ea-5c3758bff8c4"
   },
   "outputs": [],
   "source": [
    "# Sex vs Severity plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15edcae-eb9c-417a-80ca-7976debba8e2",
   "metadata": {
    "id": "e15edcae-eb9c-417a-80ca-7976debba8e2"
   },
   "source": [
    "### Question 1.2: What can you say about the relations of `Consolidation`, `GGO` and `Sex` with the `Severity` of COVID?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2030f795-0239-4426-bda2-ce7f29b386f9",
   "metadata": {
    "id": "2030f795-0239-4426-bda2-ce7f29b386f9"
   },
   "source": [
    "Answer to Question 1.2: ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13e18c-7086-4d60-afb8-a431f9879fa9",
   "metadata": {
    "id": "aa13e18c-7086-4d60-afb8-a431f9879fa9"
   },
   "source": [
    "***\n",
    "## Part 2:  Logistic regression of severity on `Age` and `Gender`\n",
    "\n",
    "Logistic regression allows us to analyze how a set of features affects some binary target label. The weights gives us an estimation of the influence of each particular feature on the probability of the target being equal to one.\n",
    "\n",
    "We want to model how the probability that a person develops a severe COVID disease is affected by his/her age, sex, and size lung lesions.\n",
    "\n",
    "Let $y_i = 1$ if i-th person's develop severe symptoms.\n",
    "Logistic regression models this probabilty in the following way:\n",
    "\n",
    "\\begin{equation}\n",
    "p(y_i = 1 \\mid \\beta) = \\sigma (\\alpha + \\beta_0 age_i + \\beta_1 sex_i + \\dots ),\n",
    "\\end{equation}\n",
    "\n",
    "where $\\sigma(t) = \\frac1{1 + e^{-t}}$\n",
    "\n",
    "We can obtain a point estimate for the intercept $\\alpha$ and coefficients $\\beta_k$ using *sklearn* package.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbad73e-f732-4933-8d39-86c5b7542137",
   "metadata": {
    "id": "9cbad73e-f732-4933-8d39-86c5b7542137"
   },
   "source": [
    "### Task 2.1: Define the logistic function\n",
    "\n",
    "To compute probabilities with the logistic regresion, we first need to define the logistic functions. Use `numpy` and complete the code function below so it returns the logistic function $\\sigma(t) = \\frac1{1 + e^{-t}}$.\n",
    "\n",
    "Test your system. The `logistic(1)` should return a value of `+- 0.731`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7689df36-6129-4561-b2be-c15ece0c3b47",
   "metadata": {
    "id": "7689df36-6129-4561-b2be-c15ece0c3b47"
   },
   "outputs": [],
   "source": [
    "def logistic(x):\n",
    "    # Your code here\n",
    "\n",
    "    return logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b681cf-27bc-414f-8595-6fe1ff38e5df",
   "metadata": {
    "id": "82b681cf-27bc-414f-8595-6fe1ff38e5df"
   },
   "source": [
    "### Task 2.2: Fit a logistic regresion model.\n",
    "Now lets fit a logistic regression model for COVID severity. This first basic model will only consider two features. We thus have to create a feature set ```X``` by only selecting the ```age``` and ```sex``` columns of the total ```df```. Make sure that age is the first feature column during the whole lab session! Use the logistic regression model (with all default parameters) of ```scikit-learn``` to create and fit the model. Then, print the values of coefficients and the interception of the fitted model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b99235-8e56-4c36-8f77-e4abbdfde410",
   "metadata": {
    "id": "e2b99235-8e56-4c36-8f77-e4abbdfde410"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bda3341-b837-460a-99d5-517a9308dcf9",
   "metadata": {
    "id": "9bda3341-b837-460a-99d5-517a9308dcf9"
   },
   "source": [
    "### Question 2.1: What do the coefficients and interceptions mean ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3e989b-90a5-4297-9372-9f59b395d2c6",
   "metadata": {
    "id": "5b3e989b-90a5-4297-9372-9f59b395d2c6"
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f6abb6a-d274-4b50-bc4e-b3a63dbcfcc5",
   "metadata": {
    "id": "0f6abb6a-d274-4b50-bc4e-b3a63dbcfcc5"
   },
   "source": [
    "### Task 2.3: Computing severity risks with the obtained model\n",
    "Now manually compute the probability of severity with the obtained coefficients. Use your own defined logistic function and the formula presented in task 2.1. Compare the probability of severe disease  of the following patients:\n",
    "- 60y old male\n",
    "- 50y old woman.\n",
    "- 35y old male\n",
    "- 40y old woman\n",
    "\n",
    "\n",
    "__Hint__: Represent all features in one numpy array with shape 4 ( patients) by 2 (features). Can you re write the Formula given in task 2 as a Matrix multiplication? A matrix multiplicatoin can be performed by the '@' operation on numpy arrays, Transprosing matrixes with '.T' can also be usefull!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d568acee-a2d4-4a8d-a978-e6bacd860728",
   "metadata": {
    "id": "d568acee-a2d4-4a8d-a978-e6bacd860728"
   },
   "outputs": [],
   "source": [
    "#Your Code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11562aeb-b96d-41be-9f38-5ff7e82a348d",
   "metadata": {
    "id": "11562aeb-b96d-41be-9f38-5ff7e82a348d"
   },
   "source": [
    "### Task 2.4: Plotting severity curves\n",
    "In task 1.3, you where asked to plot the mean severity for different ages per gender in a scatter plot. In task 2.3, you got probabilities of severity for specific age,sex combinations. Now print 2 curves representing the probability of having severe COVID per age for all ages between 20 and 100. On the same plot, also plot the results obtained from task 1.3.\n",
    "\n",
    "__hint__: Manually define X\n",
    "\n",
    "__hint__: Use np.linspace to contstruct an array of all possible ages between 20 and 100\n",
    "\n",
    "__hint__: np.vstack can be usefull to concatenate 2 np arrays. You can use it to construct X\n",
    "\n",
    "__hint__: Create an X matrix representing males, and a seperate X matrix for females. You can then easily plot them in different colours\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eb26a2-044b-4a6d-a63a-e69ed2daaecd",
   "metadata": {
    "id": "32eb26a2-044b-4a6d-a63a-e69ed2daaecd"
   },
   "outputs": [],
   "source": [
    "#Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1c5a1e-7e30-4d60-8135-715420db066d",
   "metadata": {
    "id": "1c1c5a1e-7e30-4d60-8135-715420db066d"
   },
   "source": [
    "### Question 2.2: This function does not look like a standard sigmoid function, why ? What can you say about the relation between age, gender and severity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b948b8-7d3c-4d91-980d-cb4adb61167f",
   "metadata": {
    "id": "90b948b8-7d3c-4d91-980d-cb4adb61167f"
   },
   "outputs": [],
   "source": [
    "#Your answer here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3558e8-9d24-410b-bd8c-b2a1dd315495",
   "metadata": {
    "id": "0a3558e8-9d24-410b-bd8c-b2a1dd315495"
   },
   "source": [
    "# Part 3: Confidence intervals\n",
    "\n",
    "This model already gives us a trend on the impact of COVID severity. But how certain are we on the obtained results? The confidence intervals can be obtained using the method of bootstrapping. By fitting the model 1000 times on random subsets of the dataset, we can obtain 1000 sets of coefficients and interceptions of the model that we can later analyse. We estimate the parameter for many random samples of the population and obtain an approximation of the sampling distribution of the coefficient estimate. This method is very general, as it is independent of the estimator and makes fewer assumptions than other methods.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a15e9a-0072-4e18-9b11-9fbe6d284cce",
   "metadata": {
    "id": "a6a15e9a-0072-4e18-9b11-9fbe6d284cce"
   },
   "source": [
    "### Task 3.1: Obtain Bootstrap results:\n",
    "\n",
    "Fit 1000 models on random subsets of the data with replacement. every dataset sample with give you 1 set of parameters.\n",
    "\n",
    "__hint__: Use the pandas.sample function with replacement to draw a bootstrap sample with the same size as the original df\n",
    "__hint2__: Make sure that you store the coeficients and the intercepts in the lists provided by us, later you will need them to plot the confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ce1f2d-7895-4f1b-8c88-876b1c33294a",
   "metadata": {
    "id": "c9ce1f2d-7895-4f1b-8c88-876b1c33294a"
   },
   "outputs": [],
   "source": [
    "N_bs = 1000\n",
    "coef_bs = np.zeros([2,N_bs])\n",
    "int_bs = np.zeros([1,N_bs])\n",
    "\n",
    "\n",
    "for i in range(N_bs):\n",
    "  #YOur code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796090cd-08df-4ecd-9be3-76417fd4a03e",
   "metadata": {
    "id": "796090cd-08df-4ecd-9be3-76417fd4a03e"
   },
   "source": [
    "\n",
    "### 3.2: Visualization and analysis of results\n",
    "\n",
    "The code snippit below plots confidence intervals for a bootstrapped model, Use it together with your code in task 2.4 to plot confidence interval around the obtained curves from task 2.4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d178e5ec-53e7-47f0-ab45-28204f5b50e5",
   "metadata": {
    "id": "d178e5ec-53e7-47f0-ab45-28204f5b50e5"
   },
   "outputs": [],
   "source": [
    "# This function plots confidence intervals for a set of bootstrapped intercepts and coeficients.\n",
    "# You also have to provide the values on the x_axis,and a colour scheme\n",
    "def plot_CI(int_bs,coef_bs,X,color):\n",
    "    CI = np.percentile(logistic(int_bs.T + coef_bs.T @ X), [2.5, 97.5], axis=0)\n",
    "    plt.fill_between(X[0], CI[0], CI[1], color=color, alpha=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1921b3-a9ad-4dff-8d92-3832c6520a61",
   "metadata": {
    "id": "4b1921b3-a9ad-4dff-8d92-3832c6520a61"
   },
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c91502d9-fa11-4356-af05-4a61bf3002af",
   "metadata": {
    "id": "c91502d9-fa11-4356-af05-4a61bf3002af"
   },
   "source": [
    "### Question 3.1: What can you conclude from this graph. What does it mean that the confidence intervals don't overlap?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dffdcc2-c926-4cce-842e-d94e79c7958a",
   "metadata": {
    "id": "7dffdcc2-c926-4cce-842e-d94e79c7958a"
   },
   "outputs": [],
   "source": [
    "# Answer to question 3.1: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73ad878-cdec-43ad-9a72-0c2eada62a12",
   "metadata": {
    "id": "e73ad878-cdec-43ad-9a72-0c2eada62a12"
   },
   "source": [
    "***\n",
    "## Part 4: Add `GGO` and `Consolidation`  \n",
    "\n",
    "The previous model only explored the gender and age effect. In this part, we are going to add the `GGO` and `Consolidation` to the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd25344-e512-447b-8a35-a63e739ad830",
   "metadata": {
    "id": "afd25344-e512-447b-8a35-a63e739ad830"
   },
   "source": [
    "### Task 4.1.\n",
    "\n",
    "Similar to the code provided in Part 2, retrain the model on all 4 features. Print the coefficients and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76597ed-f094-44ab-ac94-e6b8a7d16a17",
   "metadata": {
    "id": "e76597ed-f094-44ab-ac94-e6b8a7d16a17"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e168dddd-63c0-4f4b-89c6-d1667043463a",
   "metadata": {
    "id": "e168dddd-63c0-4f4b-89c6-d1667043463a"
   },
   "source": [
    "### Question 4.1: The shape of the coefficient vector has changed, what do the values represent? Based on these values, what feature do you expect to have the highest impact on disease severity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4482405-4e89-496a-96ae-474277b15c9f",
   "metadata": {
    "id": "a4482405-4e89-496a-96ae-474277b15c9f"
   },
   "outputs": [],
   "source": [
    "# Answer to question 3.1: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301825c1-ea68-44c8-b51d-0d4059574c25",
   "metadata": {
    "id": "301825c1-ea68-44c8-b51d-0d4059574c25"
   },
   "source": [
    "### Task 4.2: Use the bootstrapping technique to create the confidence interval for the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adacc9a-738b-489a-b367-781f1ece8c0c",
   "metadata": {
    "id": "5adacc9a-738b-489a-b367-781f1ece8c0c"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcfc69-066a-48e0-b277-9a2e9348c894",
   "metadata": {
    "id": "5cfcfc69-066a-48e0-b277-9a2e9348c894"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "N_bs = 1000\n",
    "coef_bs_1 = np.zeros([4,N_bs])\n",
    "int_bs_1 = np.zeros([1,N_bs])\n",
    "\n",
    "for i in range(N_bs):\n",
    "  #your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035b6bb3-5869-4025-a39f-040cb7a52b3b",
   "metadata": {
    "id": "035b6bb3-5869-4025-a39f-040cb7a52b3b"
   },
   "source": [
    "### Tasks 4.3: Visualize the results of ```consolidation``` and ```GGO```:\n",
    "As we now have multi-dimensional and continous data, we have to apply some tricks to plot the results.\n",
    "Firstly, to reduce the dimensionality, we will only focus on males.\n",
    "Secondly, a logistic regression model is a linear model, we can simply average out features.\n",
    "\n",
    "Furthermore, ```consolidation``` and ```GGO``` are continous values. To assess their full impact, we will use the 10th and 90th percentiles. This reflects a 'High' or 'Low' value of ```consolidation``` and ```GGO```\n",
    "\n",
    "__Hint 1:__ Create X such that you only have males.\n",
    "\n",
    "__Hint 2:__ Set the ```GGO``` value to its mean in ```X``` when inspecting the impact of ```consolidation``` and vise versa.\n",
    "\n",
    "__Hint 3:__ To create 2 plots, use the 10th and 90th percentile values in ```X``` for the feature of interest. (with np.percenile)\n",
    "\n",
    "__Hint 4:__ You do not need to have the pointplots here as we do not have cathegorical data for the ```GGO``` and ```consolidation```.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a73268-67fa-4632-8434-23902bf5f941",
   "metadata": {
    "id": "57a73268-67fa-4632-8434-23902bf5f941"
   },
   "outputs": [],
   "source": [
    "# Code for impact of GGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eba1be-8b92-436f-bf7b-0105081e70a9",
   "metadata": {
    "id": "41eba1be-8b92-436f-bf7b-0105081e70a9"
   },
   "outputs": [],
   "source": [
    "# code for impact of Consolidation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ac76d1-0e1b-4d0d-ba62-8ba40aec3bbd",
   "metadata": {
    "id": "e6ac76d1-0e1b-4d0d-ba62-8ba40aec3bbd"
   },
   "source": [
    "### Question 4.2: What can you say on the impact on severity from `GGO` and `Consolidation`? Which one has the highest impact ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712838d4-e104-4285-9fb9-9857c7952d5e",
   "metadata": {
    "id": "712838d4-e104-4285-9fb9-9857c7952d5e"
   },
   "outputs": [],
   "source": [
    "# Answer to Question 3.2: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24757f2-5714-4f5c-ae37-929505694050",
   "metadata": {
    "id": "b24757f2-5714-4f5c-ae37-929505694050"
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "#There is no additional risk increase due to consolodiation for age and GGO fixed.\n",
    "\n",
    "#Effect of GGO on severity risk is large, approximately 50% increase for people of 60 years old.\n",
    "# This is larger than the age effect, which is lower thatn 40% in the whole range of age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25aef59c-0746-41ab-81d2-0fa8575986e5",
   "metadata": {
    "id": "25aef59c-0746-41ab-81d2-0fa8575986e5"
   },
   "source": [
    "### Question 4.3: Does this insight agrees with your answer to Q3.1? Why could this happen?\n",
    "__Hint:__ Have a look at the density plots you made in Part 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182af7a-94ef-45f7-b488-21eae5e945a2",
   "metadata": {
    "id": "8182af7a-94ef-45f7-b488-21eae5e945a2"
   },
   "outputs": [],
   "source": [
    "# Answer to Question 3.3: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4225c6e1-408b-404a-80c1-5089e41d2811",
   "metadata": {
    "id": "4225c6e1-408b-404a-80c1-5089e41d2811"
   },
   "source": [
    "## Part 5: Cost functions\n",
    "\n",
    "After extracting knowledge from the data, it is time to put the logistic regression models into action.\n",
    "\n",
    "You are working in an insurance company, and you have to advice the government what kind of financial model they should use to treat COVID-19 patients. The two options on the table are the logistic regression models trained on 2 (i.e. ```Age``` and ```Sex```) or on 4 features (i.e. ```Age```, ```Sex```, ```GGO```, ```Consolidation```).\n",
    "\n",
    "Use decision curve analysis to investigate the 2 options.\n",
    "\n",
    "__Hint 1:__ As you will now use the models to make predictions, it is nescacary to split your dataset in a train and test split. Use sklearn for this and use a test split of size 33%.\n",
    "\n",
    "__Hint 2:__ First, train your logistic regression model on 2 and later on 4 features. Use ```sklearn``` function ```predict_proba()``` to get probability values for your ```X```.\n",
    "\n",
    "__Hint 3:__ Use the ```NetBenefitDisplay``` function from the ```statkit``` package to plot the curves.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tdKB-voHm9fw",
   "metadata": {
    "id": "tdKB-voHm9fw"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8916d8b2-39ba-4272-8220-f510e7926e62",
   "metadata": {
    "id": "8916d8b2-39ba-4272-8220-f510e7926e62"
   },
   "source": [
    "### Question 5.1: What model would you advice to use. Explain with the help of the curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec56e783-a0b6-45ca-90cd-4a65c686658e",
   "metadata": {
    "id": "ec56e783-a0b6-45ca-90cd-4a65c686658e"
   },
   "outputs": [],
   "source": [
    "# Your answer here..."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
